{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Thierry\\Desktop\\MILA\\Session 01\\IFT6758\\project-template\\ift6758\\models\\wandb\\run-20241122_204430-lsa06j2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/IFT67582024-A07/Models%20Test/runs/lsa06j2y' target=\"_blank\">dashing-meadow-1</a></strong> to <a href='https://wandb.ai/IFT67582024-A07/Models%20Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/IFT67582024-A07/Models%20Test' target=\"_blank\">https://wandb.ai/IFT67582024-A07/Models%20Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/IFT67582024-A07/Models%20Test/runs/lsa06j2y' target=\"_blank\">https://wandb.ai/IFT67582024-A07/Models%20Test/runs/lsa06j2y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/IFT67582024-A07/Models%20Test/runs/lsa06j2y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1f322c4f640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure WandB\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"Models Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "play_by_play_path = \"../../data/dataframe_2020_to_2021.csv\"\n",
    "play_by_play = pd.read_csv(play_by_play_path)\n",
    "\n",
    "# Filter for regular-season games and remove missing values\n",
    "play_by_play = play_by_play.dropna()\n",
    "\n",
    "# Remove non-relevant features\n",
    "X_all_features = play_by_play.drop(play_by_play.columns[[1, 2, 3, 5, 6, 14, 15, 16, 18, 19, 20, 21]], axis=1)\n",
    "features_to_encode = [\"previousEventType\", \"shotType\"]\n",
    "\n",
    "# Encode categorical features\n",
    "def encode_and_bind(df, feature):\n",
    "    dummies = pd.get_dummies(df[feature], prefix=feature)\n",
    "    return pd.concat([df.drop(columns=feature), dummies], axis=1)\n",
    "\n",
    "# Apply encoding on selected features\n",
    "for feature in features_to_encode:\n",
    "    X_all_features = encode_and_bind(X_all_features, feature)\n",
    "\n",
    "X_shot_distance = play_by_play[[\"shotDistance\"]]\n",
    "X_shot_angle = play_by_play[[\"shotAngle\"]]\n",
    "X_shot_distance_angle = play_by_play[[\"shotDistance\", \"shotAngle\"]]\n",
    "\n",
    "y = play_by_play[\"isGoal\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all_features shape: (313765, 31)\n",
      "y shape: (313765,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_all_features shape: {X_all_features.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Registries can be linked/fetched using a shorthand form without specifying the organization name. Try using shorthand path format: <my_registry_name>/<artifact_name> or just <my_registry_name> if fetching just the project.\n",
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Thierry\\\\Desktop\\\\MILA\\\\Session 01\\\\IFT6758\\\\project-template\\\\ift6758\\\\models\\\\artifacts\\\\Logistic_regression_distance-v0/model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m lr_distance_artifact\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Thierry\\\\Desktop\\\\MILA\\\\Session 01\\\\IFT6758\\\\project-template\\\\ift6758\\\\models\\\\artifacts\\\\Logistic_regression_distance-v0/model.joblib'"
     ]
    }
   ],
   "source": [
    "lr_distance_artifact = wandb.use_artifact('philippe-bergeron-7-universit-de-montr-al-org/wandb-registry-model/Logistic regression:v2', type='model')\n",
    "lr_distance_artifact_dir = lr_distance_artifact.download()\n",
    "\n",
    "model_path = f\"{lr_distance_artifact_dir}/logistic_regression_distance.pkl\"\n",
    "lr_distance_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_angle_artifact = wandb.use_artifact('philippe-bergeron-7-universit-de-montr-al-org/wandb-registry-model/Logistic regression:v3', type='model')\n",
    "lr_angle_artifact_dir = lr_angle_artifact.download()\n",
    "\n",
    "model_path = f\"{lr_angle_artifact_dir}/logistic_regression_angle.pkl\"\n",
    "lr_angle_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_distance_angle_artifact = wandb.use_artifact('philippe-bergeron-7-universit-de-montr-al-org/wandb-registry-model/Logistic regression:v3', type='model')\n",
    "lr_distance_angle_artifact_dir = lr_distance_angle_artifact.download()\n",
    "\n",
    "model_path = f\"{lr_distance_angle_artifact_dir}/logistic_regression_distance_angle.pkl\"\n",
    "lr_distance_angle_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evauluate the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_artifact = wandb.use_artifact('philippe-bergeron-7-universit-de-montr-al-org/wandb-registry-model/Random Forest:v0', type='model')\n",
    "random_forest_artifact_dir = random_forest_artifact.download()\n",
    "\n",
    "model_path = f\"{random_forest_artifact_dir}/XGBoost_Model.pkl\"\n",
    "xgboost_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Registries can be linked/fetched using a shorthand form without specifying the organization name. Try using shorthand path format: <my_registry_name>/<artifact_name> or just <my_registry_name> if fetching just the project.\n",
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "random_forest_artifact = wandb.use_artifact('philippe-bergeron-7-universit-de-montr-al-org/wandb-registry-model/Random Forest:v0', type='model')\n",
    "random_forest_artifact_dir = random_forest_artifact.download()\n",
    "\n",
    "model_path = f\"{random_forest_artifact_dir}/RandomForest_Model.pkl\"\n",
    "rf_model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_figures(model, X, y, model_name):\n",
    "    # Generate predictions and probabilities\n",
    "    y_pred_probs = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Random baseline\n",
    "    np.random.seed(42)\n",
    "    prob_random = np.random.uniform(0, 1, len(y))\n",
    "\n",
    "    # **1. ROC Curve and AUC**\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, prob in [\n",
    "        (\"Modèle\", y_pred_probs),\n",
    "        (\"Aléatoire\", prob_random),\n",
    "    ]:\n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(y, prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
    "    plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
    "    plt.title(f\"Courbe ROC - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # **2. Goal Rate by Probability Percentile**\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, prob in [\n",
    "        (\"Modèle\", y_pred_probs),\n",
    "        (\"Aléatoire\", prob_random),\n",
    "    ]:\n",
    "        sorted_indices = np.argsort(prob)\n",
    "        prob_sorted = np.array(prob[sorted_indices])\n",
    "        y_sorted = np.array(y[sorted_indices])\n",
    "\n",
    "        percentiles = np.percentile(prob_sorted, np.arange(0, 101, 10))\n",
    "        goal_rates = [\n",
    "            y_sorted[(prob_sorted >= percentiles[i]) & (prob_sorted < percentiles[i + 1])].mean()\n",
    "            if np.sum((prob_sorted >= percentiles[i]) & (prob_sorted < percentiles[i + 1])) > 0\n",
    "            else 0\n",
    "            for i in range(len(percentiles) - 1)\n",
    "        ]\n",
    "        plt.plot(np.arange(0, 100, 10), [rate * 100 for rate in goal_rates], label=name)\n",
    "\n",
    "    plt.xlabel(\"Centile de la probabilité prédite\")\n",
    "    plt.ylabel(\"Taux de buts (%)\")\n",
    "    plt.title(f\"Taux de buts par centile de probabilité - {model_name}\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # **3. Cumulative Goal Proportion**\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, prob in [\n",
    "        (\"Modèle\", y_pred_probs),\n",
    "        (\"Aléatoire\", prob_random),\n",
    "    ]:\n",
    "        sorted_indices = np.argsort(prob)[::-1]\n",
    "        y_sorted = np.array(y)[sorted_indices]\n",
    "\n",
    "        cumulative_goals = np.cumsum(y_sorted)\n",
    "        total_goals = np.sum(y_sorted)\n",
    "\n",
    "        cumulative_goal_proportion = cumulative_goals / total_goals\n",
    "\n",
    "        centiles = np.linspace(100, 0, len(cumulative_goal_proportion))\n",
    "        plt.plot(centiles, cumulative_goal_proportion * 100, label=name)\n",
    "\n",
    "    plt.xlabel(\"Centile de la probabilité prédite\")\n",
    "    plt.ylabel(\"Proportion cumulée des buts (%)\")\n",
    "    plt.title(f\"Proportion cumulée des buts par centile de probabilité - {model_name}\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # **4. Calibration Curve**\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, prob in [\n",
    "        (\"Modèle\", y_pred_probs),\n",
    "        (\"Aléatoire\", prob_random),\n",
    "    ]:\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(y, prob, n_bins=10, strategy=\"quantile\")\n",
    "        plt.plot(mean_predicted_value, fraction_of_positives, label=name)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Calibration parfaite\")\n",
    "    plt.xlabel(\"Probabilité prédite\")\n",
    "    plt.ylabel(\"Fréquence observée (empirique)\")\n",
    "    plt.title(f\"Diagramme de fiabilité (Calibration) - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figures for each model\n",
    "generate_figures(lr_distance_model, X_shot_distance, y, \"Logistic Regression (Distance)\")\n",
    "generate_figures(lr_angle_model, X_shot_angle, y, \"Logistic Regression (Angle)\")\n",
    "generate_figures(lr_distance_angle_model, X_shot_distance_angle, y, \"Logistic Regression (Distance + Angle)\")\n",
    "generate_figures(rf_model, X_all_features, y, \"Random Forest\")\n",
    "generate_figures(xgboost_model, X_all_features, y, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 15)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_figures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_all_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandom Forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m, in \u001b[0;36mgenerate_figures\u001b[1;34m(model, X, y, model_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_figures\u001b[39m(model, X, y, model_name):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Generate predictions and probabilities\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     y_pred_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m      4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Random baseline\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Thierry\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1087\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1088\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1091\u001b[0m         )\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 15)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "generate_figures(rf_model, X_all_features, y, \"Random Forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
